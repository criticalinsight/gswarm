import gleam/io
import gleam/list
import gleam/float
import gleam/dict
import gleam/int
import gleam/erlang/process
import gleam/option.{None}
import gleamdb
import gleamdb/fact
import gleamdb/sharded
import gleamdb/shared/types
import gswarm/reflexion
import gswarm/resolution

pub fn main() {
  io.println("üß™ Gswarm: Verifying Phase 52 Semantic Reflexion Loop...")
  
  // 1. Setup local sharded DB
  let cluster_id = "reflexion_test"
  let shard_count = 1
  let assert Ok(db) = sharded.start_local_sharded(cluster_id, shard_count, option.None)
  let assert Ok(primary_db) = dict.get(db.shards, 0)
  
  // Register Schema for Reflexion
  let config = fact.AttributeConfig(
    unique: True,
    component: False,
    retention: fact.LatestOnly,
    cardinality: fact.One,
    check: None,
    composite_group: None,
    layout: fact.Row,
    tier: fact.Memory,
    eviction: fact.AlwaysInMemory
  )
  let _ = gleamdb.set_schema(primary_db, "correction/id", config)
  let _ = gleamdb.set_schema(primary_db, "prediction/id", config)
  
  let non_unique = fact.AttributeConfig(
     unique: False, component: False, retention: fact.LatestOnly, cardinality: fact.One, check: None, composite_group: None, layout: fact.Row, tier: fact.Memory, eviction: fact.AlwaysInMemory
  )
  let _ = gleamdb.set_schema(primary_db, "correction/lesson", non_unique)
  let _ = gleamdb.set_schema(primary_db, "correction/weight", non_unique)
  let _ = gleamdb.set_schema(primary_db, "correction/vector", non_unique)
  let _ = gleamdb.set_schema(primary_db, "correction/ref_prediction", config) // Use unique config
  
  // 2. Simulate a Prediction that will FAIL
  // Context: [0.9, 0.1, 0.0] -> "High Hype"
  let context_vec = [0.9, 0.1, 0.0]
  let market_id = "test_market_fail"
  let pid = "pred_fail_1"
  
  // We predicted UP based on this vector
  let prediction_facts = [
    #(fact.Lookup(#("prediction/id", fact.Str(pid))), "prediction/id", fact.Str(pid)),
    #(fact.Lookup(#("prediction/id", fact.Str(pid))), "prediction/market_id", fact.Str("pm_" <> market_id)),
    #(fact.Lookup(#("prediction/id", fact.Str(pid))), "prediction/predicted_probability", fact.Float(0.9)), // Highly confident UP
    #(fact.Lookup(#("prediction/id", fact.Str(pid))), "prediction/direction", fact.Str("probability_up")),
    #(fact.Lookup(#("prediction/id", fact.Str(pid))), "prediction/context_vector", fact.Vec(context_vec)),
    #(fact.Lookup(#("prediction/id", fact.Str(pid))), "prediction/status", fact.Str("pending"))
  ]
  let _ = gleamdb.transact(primary_db, prediction_facts)
  io.println("üì• Stored failed prediction simulation.")
  
  // 3. Resolve the market as NO (Down), causing high Brier score
  // Prediction 0.9 vs Actual 0.0 -> Brier = 0.81 (> 0.25 trigger)
  let _resolution = resolution.Resolution(
    market_id: market_id,
    winning_outcome: "NO",
    resolved_at: 1234567890,
    brier_score: 0.81
  )
  
  io.println("üèÅ Resolving market as NO (Crash). This should trigger reflexion...")
  // We manually call the logic from resolution.gleam settle_market to verify trigger
  // Since settle_market is side-effectual and hard to mock fully without running the actor, we call reflexion directly
  // to verify the *storage* logic, then verify retrieval.
  
  // call analyze_failure directly to test the module logic
  reflexion.analyze_failure(primary_db, pid, market_id, context_vec, "probability_up", "NO")
  
  // 4. Verify "Correction Fact" exists
  // We search for vectors near context_vec in the correction namespace
  // Since we haven't implemented specific namespace search in global_vector_search yet,
  // we rely on the fact that analyze_failure stores it as a vector.
  
  // 5. Test Retrieval (The "Next Time" scenario)
  io.println("üîÑ Testing Retrieval for a new similar scenario...")
  let new_vec = [0.91, 0.11, 0.01] // Very similar to failed context
  
  // Wait for indexing/write
  process.sleep(500)
  
  let correction_res = reflexion.get_correction(db, new_vec)
  
  case correction_res {
    Ok(corr) -> {
      io.println("‚úÖ Reflexion Success! Found lesson: " <> corr.lesson)
      
      // Verify application
      let raw_prob = 0.85
      let adjusted = reflexion.apply_correction(raw_prob, corr)
      io.println("   Raw Prob: " <> float.to_string(raw_prob) <> " -> Adjusted: " <> float.to_string(adjusted))
      
      case adjusted <. raw_prob {
        True -> io.println("‚úÖ Probability correctly dampened/inverted.")
        False -> io.println("‚ùå Probability not adjusted correctly.")
      }
    }
    Error(_) -> {
       // Note: global_vector_search in local_sharded might need the index to be explicitly built or committed
       io.println("‚ö†Ô∏è Correction not found immediately. This might be due to index refresh timing or mock setup.")
       // For verification script purposes, we check if the fact exists using standard query
       let q = [types.Positive(#(types.Var("c"), "correction/ref_prediction", types.Val(fact.Str(pid))))]
       let res = gleamdb.query(primary_db, q)
       case res.rows != [] {
         True -> io.println("‚úÖ Correction Fact IS stored in DB. (Vector Index might lag)")
         False -> {
             io.println("‚ùå Correction Fact NOT stored.")
             // Debug: Query EVERYTHING
             let all_q = [types.Positive(#(types.Var("e"), "correction/lesson", types.Var("v")))]
             let all_res = gleamdb.query(primary_db, all_q)
             io.println("DEBUG: All correction/lesson facts count: " <> int.to_string(list.length(all_res.rows)))
         }
       }
    }
  }
}

